# Техническое видение проекта

## 1. Технологии

### Обязательные технологии
- **Python** (3.11+) — основной язык разработки
- **uv** — управление зависимостями и виртуальными окружениями
- **aiogram** (3.x) — интеграция с Telegram Bot API через метод polling
- **openai** — клиент для работы с LLM через провайдер OpenRouter
- **make** — команды для сборки и запуска проекта

### Дополнительные библиотеки
- **python-dotenv** — загрузка конфигурации из файла `.env`
- **logging** (встроенный модуль Python) — логирование работы приложения

## 2. Принцип разработки

### Философия подхода

- **MVP-подход** — создаём минимальную рабочую версию для проверки идеи
- **KISS** — избегаем лишних абстракций и усложнений
- **YAGNI** — реализуем только то, что нужно сейчас

### Этапы разработки

1. **Настройка окружения** — создание проекта, установка зависимостей
2. **Базовый бот** — приём сообщений от пользователя
3. **Интеграция с LLM** — отправка сообщения в модель, получение ответа
4. **Обработка диалога** — поддержание контекста разговора
5. **Тестирование** — проверка базового сценария работы

## 3. Структура проекта

```
project/
├── .env                 # конфигурация (токены, ключи API)
├── pyproject.toml       # зависимости проекта через uv
├── Makefile             # команды для сборки и запуска
├── bot.py               # точка входа - запуск бота
├── config.py            # загрузка конфигурации из .env
├── llm_client.py        # интеграция с LLM через OpenRouter
└── handlers.py          # обработчики сообщений от пользователей
```

### Описание файлов

- **.env** — переменные окружения (токены, ключи API)
- **pyproject.toml** — описание зависимостей проекта
- **Makefile** — команды для запуска и тестирования
- **bot.py** — точка входа, запуск Telegram бота
- **config.py** — загрузка конфигурации из файла .env
- **llm_client.py** — клиент для взаимодействия с LLM через OpenRouter
- **handlers.py** — логика обработки сообщений от пользователей

## 4. Архитектура проекта

### Компоненты системы

```
Пользователь → Telegram API → Bot (handlers.py)
                                      ↓
                                LLM Client (llm_client.py)
                                      ↓
                                OpenRouter → LLM
                                      ↓
                                Ответ ←──────┘
                                      ↓
                                Bot отправляет пользователю
```

### Компоненты

- **handlers.py** — принимает сообщения пользователя и отправляет ответы
- **llm_client.py** — формирует запрос, вызывает LLM и возвращает ответ
- **config.py** — поставляет конфигурацию (токены, ключи API)
- **bot.py** — запускает бота и объединяет все компоненты

### Поток данных

1. Пользователь отправляет сообщение в Telegram
2. **handlers.py** получает сообщение и передаёт в **llm_client.py**
3. **llm_client.py** формирует запрос и отправляет в LLM через OpenRouter
4. LLM возвращает ответ в **llm_client.py**
5. **handlers.py** отправляет ответ пользователю в Telegram

## 5. Модель данных

### Типы данных

```
1. Message — сообщение пользователя (текст)
2. UserContext — контекст диалога с пользователем
   - user_id: int
   - message_history: list[dict]  # история сообщений
```

### Хранение данных

- **В памяти** — словарь по user_id для хранения контекста диалога
- **Без персистентности** — данные теряются при перезапуске бота
- **Минимально необходимый объём** — только для поддержания диалога

## 6. Работа с LLM

### Интеграция через OpenRouter

- **API ключ** — в конфигурации `.env`
- **Endpoint**: `https://openrouter.ai/api/v1/chat/completions`
- **Модель** — настраивается в конфигурации (например, `openai/gpt-4`)

### Структура запроса

- **system_message** — роль банковского консультанта (в системном промпте)
- **messages** — история диалога с пользователем
- **model** — выбранная LLM модель

### Структура ответа

- **text** — текст ответа для пользователя

### Формирование контекста

- **Системный промпт**: роль профессионального консультанта банка (описание из idea.md)
- **История сообщений**: последние N сообщений для поддержания контекста диалога
- **Новое сообщение пользователя**: добавляется в историю перед отправкой в LLM

### Параметры

- **temperature** — уровень креативности ответов (настраивается в конфигурации)
- **max_tokens** — максимальная длина ответа (настраивается в конфигурации)

## 7. Сценарии работы

### Базовый сценарий

1. Пользователь отправляет сообщение в Telegram боту
2. Бот получает сообщение, формирует историю диалога
3. Бот отправляет запрос в LLM через OpenRouter
4. LLM возвращает ответ в роли банковского консультанта
5. Бот отправляет ответ пользователю

### Обработка ошибок

- **Ошибка подключения к LLM** → сообщение пользователю об ошибке
- **Превышен лимит токенов** → укорачивание истории сообщений
- **Таймаут запроса** → сообщение пользователю, ошибка логируется

### Дополнительные сценарии (по необходимости)

- **Команда `/start`** — приветственное сообщение от бота
- **Сброс контекста диалога** — команда для начала нового диалога

## 8. Подход к конфигурированию

### Файл конфигурации: `.env`

### Переменные

**Обязательные:**
- `TELEGRAM_BOT_TOKEN` — токен Telegram бота
- `OPENROUTER_API_KEY` — API ключ OpenRouter

**Опциональные:**
- `LLM_MODEL` — модель LLM (по умолчанию: `openai/gpt-4`)
- `LLM_TEMPERATURE` — температура (по умолчанию: `0.7`)
- `LLM_MAX_TOKENS` — максимальное количество токенов (по умолчанию: `1000`)
- `MAX_HISTORY_MESSAGES` — количество сообщений в истории (по умолчанию: `10`)

### Загрузка конфигурации

- Через `python-dotenv` в `config.py`
- Проверка наличия обязательных переменных при старте
- Значения по умолчанию для опциональных параметров

## 9. Подход к логгированию

### Использование: встроенный модуль `logging`

### Уровни логирования

- **INFO** — информация о работе (получение сообщения, отправка запроса в LLM)
- **ERROR** — ошибки (ошибки подключения, ошибки API)

### Формат логов

- Время
- Уровень
- Сообщение

### Что логируем

- **Старт бота** — уведомление о запуске
- **Получение сообщения от пользователя** — user_id и текст сообщения
- **Отправка запроса в LLM** — информация о запросе
- **Получение ответа от LLM** — подтверждение получения ответа
- **Ошибки при работе с API** — детали ошибки для диагностики
