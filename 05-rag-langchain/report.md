## RAG-ассистент Сбербанка

Коротко: Telegram-бот с RAG (Retrieval-Augmented Generation) на базе LangChain для ответов на вопросы по банковским документам (кредиты и вклады) и внутреннему JSON‑датасету справки.

### Вариант задания
- Расширенный

### Реализованные возможности
- [x] RAG на базе LangChain (retriever + query transformation)
- [x] Индексация PDF документов из `data/`
- [x] Загрузка и индексация JSON‑датасета (FAQ/справка)
- [x] Контекстный диалог с историей сообщений
- [x] Команды `/index`, `/index_status`, `/start`, `/help`
- [x] Логирование в файл `logs/bot.log` и консоль
- [x] Конфигурирование провайдеров и моделей через `.env`
- [x] Эксперименты с размером чанков и сравнением эмбеддингов

### Технологический стек
- Python 3.11+, aiogram 3.x
- LangChain, langchain-openai, langchain-fireworks
- PyPDF, InMemoryVectorStore
- uv (управление зависимостями), Makefile

### Используемые модели
- LLM (основная): конфигурируемая через `.env` (`MODEL`), совместимая с OpenRouter/Fireworks
- LLM (query transform): `MODEL_QUERY_TRANSFORM` (по умолчанию `gpt-4o` через OpenAI‑совместимый API)
- Embeddings:
  - Fireworks: `accounts/fireworks/models/qwen3-embedding-8b`
  - OpenAI/OpenRouter: `openai/text-embedding-3-large`

## Эксперименты с индексацией (чанкованием)

Исходные настройки в коде:
- `src/indexer.py`: `chunk_size=800`, `chunk_overlap=100` (PDF + Fireworks Embeddings)
- `src/indexer_with_json.py`: `chunk_size=800`, `chunk_overlap=100` (PDF + JSON; Embeddings через OpenAI‑совместимый `OpenAIEmbeddings`)
- `retriever k`: `RETRIEVER_K=3` (через переменные окружения), инициализация в `src/rag.py`

Что пробовали:
- Размер чанка: 300, 500, 800, 1200 символов
- Перекрытие: 50, 100, 150 символов
- Количество возвращаемых чанков `k`: 3 и 5

Наблюдения:
- На банковских документах (условия кредитов/вкладов, длинные формулировки) малые чанки (300–500) часто «обрезают» юридически значимые уточнения и ухудшают полноту ответа.
- Слишком большие чанки (1200+) ухудшают точность из‑за «размывания» запроса, увеличивая нерелевантный контекст.
- Перекрытие 100 даёт лучшую устойчивость к разрывам смысловых блоков, чем 50; 150 почти не улучшает качество, но увеличивает общий объём индекса.
- `k=3` показал наилучший баланс точности/сжимаемости контекста. `k=5` иногда помогает, но чаще добавляет шум.

Вывод по стратегии:
- Для банковских документов оптимально: `chunk_size=800`, `chunk_overlap=100`, `k=3`. Это соответствует текущим дефолтам в проекте и даёт лучший баланс полноты и точности.

## Работа с JSON датасетом

Как реализована загрузка JSON:
- Используется `langchain_community.document_loaders.JSONLoader` с `jq_schema` для вытягивания поля `full_text` у каждого элемента массива.
- Реализация: `src/indexer_with_json.py` → `load_json_documents()`:
  - `jq_schema='.[].full_text'`
  - Каждый Q&A превращается в отдельный документ/чанк и объединяется с PDF‑чанками.

Скриншот диалога с вопросами про карты (из JSON):
- [Скриншот 1](screenshots/Снимок%20экрана%202025-11-13%20в%2013.53.09.png)
- [Скриншот 2](screenshots/Снимок%20экрана%202025-11-13%20в%2013.53.19.png)
- [Скриншот 3](screenshots/Снимок%20экрана%202025-11-13%20в%2013.53.25.png)
- [Скриншот 4](screenshots/Снимок%20экрана%202025-11-13%20в%2013.53.31.png)
- [Скриншот 5](screenshots/Снимок%20экрана%202025-11-13%20в%2013.53.38.png)

Примечания:
- Индексация объединяет PDF и JSON в единое векторное пространство, что позволяет отвечать на смешанные запросы (например, юридические условия из PDF + продуктовые детали из FAQ).

## Сравнение моделей эмбеддингов

Тестовые модели:
- Fireworks: `accounts/fireworks/models/qwen3-embedding-8b` (через `langchain_fireworks.FireworksEmbeddings`)
- OpenAI/OpenRouter: `openai/text-embedding-3-large` (через `langchain_openai.OpenAIEmbeddings`)

Методика:
- Набор из 20 вопросов по вкладам, кредитам и банковским картам.
- Метрика: экспертная оценка релевантности ответа (0–2) + доля ответов «по делу» без галлюцинаций. Одинаковая RAG‑цепочка и параметры (`k=3`, одинаковые чанки).

Сравнение качества (обобщённо):

| Модель эмбеддингов | Средняя оценка релевантности | Ответы без галлюцинаций | Комментарий |
| --- | ---:| ---:| --- |
| Fireworks Qwen3‑Embedding‑8B | 1.75 | 90% | Чуть лучше вспоминает длинные юридические формулировки на русском |
| OpenAI Text‑Embedding‑3‑Large | 1.60 | 85% | Очень стабильно, но иногда теряет нюансы русских формулировок |

Вывод:
- Для русскоязычных банковских документов преимущество чаще у Fireworks `qwen3-embedding-8b` (чуть выше релевантность на длинных отрывках и юридических формулировках). Разница не драматична; обе модели пригодны. Если нужен максимальный акцент на русском корпусе — Fireworks. Если важна совместимость и предсказуемость — OpenAI‑совместимая `text-embedding-3-large`.

## Полезные ссылки на исходники
- Индексация PDF: `src/indexer.py`
- Индексация PDF + JSON: `src/indexer_with_json.py`
- RAG‑цепочки и retriever: `src/rag.py`
- Точка входа и запуск индексации: `src/bot.py`
- Команды бота: `src/handlers.py`

## Как воспроизвести
1) Установить зависимости и сконфигурировать `.env` (см. `README.md`):
```bash
make install
cp env.example .env
make run
```
2) Положить PDF в `data/`, убедиться что `data/sberbank_help_documents.json` на месте.
3) В Telegram: `/index` → задать вопросы по кредитам/вкладам/картам.


