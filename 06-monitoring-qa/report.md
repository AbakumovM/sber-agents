# Отчёт по проекту «RAG-ассистент Сбербанка»

## Описание проекта
- **Название:** RAG-ассистент Сбербанка  
- **Кратко:** Telegram-бот, который отвечает на вопросы по кредитным и депозитным документам Сбербанка с помощью Retrieval-Augmented Generation, поддерживает синтез датасетов и автоматическую оценку качества через LangSmith и RAGAS.
- **Вариант задания:** базовый
- **Модели и провайдеры**
  - **RAG-пайплайн:** GigaChat Lite (GigaChat API) для генерации и трансформации запросов; эмбеддинги `intfloat/multilingual-e5-base` через HuggingFace Embeddings.
  - **RAGAS evaluation:** GigaChat Lite (тот же провайдер) как LLM для метрик; эмбеддинги `intfloat/multilingual-e5-base` через HuggingFace для расчёта embedding-метрик.

## Создание и загрузка датасета
- **Подход:** комбинация автоматического синтеза вопросов/ответов из PDF документов и выборки готовых Q&A пар из JSON справочника (`sberbank_help_documents.json`).
- **Размер:** 6 примеров (по 2 из каждого PDF и по 2 из JSON).
- **Скриншот LangSmith:** [Страница датасета](screenshots/Снимок%20экрана%202025-11-20%20в%2014.11.47.png)
- **Примеры Q&A**
  1. *Вопрос:* «Какие основные разделы включены в Общие условия предоставления, обслуживания и погашения потребительского кредита?»  
     *Ответ:* «Разделы: 1) Кредит, 2) Договор, 3) Стороны, 4) Обеспечение, 5) Порядок заключения, 6) Акцепт ИУ.»
  2. *Вопрос:* «Можно ли получить обратно деньги, списанные со вклада в благотворительный фонд “Вклад в будущее”?»  
     *Ответ:* «Нет, списанная сумма не возвращается и не выплачивается вкладчику.»

## Оценка качества через RAGAS
- **Метрики:** Faithfulness, Answer Relevancy, Answer Correctness, Answer Similarity, Context Recall, Context Precision.
- **Последнее измерение (пример):** Faithfulness 0.875; Answer Relevancy 0.654; Answer Correctness 0.823; Answer Similarity 0.891; Context Recall 0.750; Context Precision 0.833.

## Выводы
- Высокие оценки Faithfulness и Context Precision подтверждают, что ответы основаны на релевантных документах без галлюцинаций.
- Answer Relevancy и Context Recall остаются средней силы из-за коротких ответов и ограниченного объёма retrieved контекста; требуется расширить датасет и увеличить разнообразие вопросов для улучшения полноты.
- Правильность и Similarity >0.8 показывают, что ответы близки к эталону при достаточном покрытии.


